---
title: "Cost Measurements (Ch 5)"
author: "James Woods"
date: ""
output:
  word_document: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



# Depreciation


## Review from Intro to Costs

Assets cost a lot and while purchased in one year provide benefits over many years. We would like to allocate cost of purchasing that asset over the years we use it (Matching principle).


+ When you buy the asset (Balance Sheet) it is in the rate base and earns interest
+ Every year some of the purchase price turns into depreciation (Income statement) and passed on the consumers.
+ Ideally, sale of an asset should result in no income changes but it almost always happens.

## Extended Numerical Example

+ Data Needed to Depreciate an Asset
    + Service Date
    + Cost Basis
    + Asset Life
    + Salvage Value
    + Method, accelerated, straight line, etc.

## Example

+ Asset goes into service now.
+ Cost 10K
+ Will last five years
+ Salvage for 2K
+ Tax uses MACRS but we will use straight line.

Depreciation each year:

$$\frac{(Cost - Salvage)}{Life} = \frac{10K - 2K}{5} = `r 8/5`K$$
The book spends a few pages doing this in percentage terms but that is more about the "Iowa Curve" methodology, what survival analysis looked like in the 1950s

## Example Continued

```{r, include=FALSE}
Dep <- data.frame(Year=c(0,1,2,3,4,5), Depreciation = 8/5, Book = 10)
Dep$Depreciation[1] <- 0
for(i in 2:6) Dep$Book[i] <- 10 - sum(Dep$Depreciation[1:i]) 

```

```{r}
library(knitr)
kable(Dep)
```

The Book Value is the cost basis less accumulated depreciation.  This is in the rate base and earns the allowable return.

## Example to Revenue Requirement

```{r, include = FALSE}
Dep$RR <- Dep$Depreciation + .1*Dep$Book
Dep$RR[1] <- 0 

```

All the depreciation is part of the revenue requirement and with an allowable rate of return of 10\%.

```{r}
library(knitr)
kable(Dep)
```

$$Revenue~Requirement = Depreciation + (.1) Book~Value$$


## Asset Retirement Obligations

Now lets add in that a site will need to be cleaned up or that it is expensive to decommission.  In this case 5K.

  + Every year, take an equal amount as an expense.
  + Add to the rate base, it earns interest in the rate base.
  + When you decommission, remove it from the rate base but don't add it as an expense since you already did.
  + $Revenue~Requirement = Depreciation + Decommission + .1 (Book~Value+ ARO)$

```{r, include =FALSE}
Dep$RR <- NA
Dep$Decomission <- 1
Dep$Decomission[1] <- 0

Dep$ARO <-0
for(i in 2:6) Dep$ARO[i] <- sum(Dep$Decomission[1:i]) 


Dep$RR <- Dep$Depreciation + Dep$Decomission + .1*(Dep$Book+Dep$ARO)
Dep$RR[1] <- 0 

```

```{r}
library(knitr)
kable(Dep)
```

# Disallowance

## Examples of Dissallowance and the Reasons Why

Disallowance is the technical term for not including an expense or an asset in the rate base.

Key terms:

+ Used and Useful: Comes from Smyth v. Ames (1898) and says physically used and useful to current rate payers before they can be asked to pay for it.  There are some exceptions.
+ Prudent:  Makes sense at the time it was made.  Not penalized for not knowing the future.


<!-- For an overview of rate making http://www.puc.state.or.us/water/water%20home%20page/Ratemaking%20Explained.pdf -->

## Examples of Dissallowance in Orgon

+ Trojan Nuclear Power Plant (PGE) as part of a larger rate case.  
+ Multiple Wind Projects (PacifiCorp) as part of a larger rate case. Costs associated with Rolling Hills was excluded. 


## Trojan

+ 1976 - 1992 
+ Only commercial Nuclear plant built in OR
+ Main issue is management problems often around maintenance
+ Many interesting aspects to this case, beyond diassallowance as well as controversy.
    + Public protests
    + Two dissenting opinions
+ Theodore Barry and Associates (TBA) 

## Trojan Key Dissallowance Part 1

After an examination of the net benefits analysis, we conclude that the premature closure of Trojan resulted in a negative net benefit of approximately $20.4 million. We find that continued operation of Trojan would have cost less than immediate shutdown but for steam generator defects and management problems at Trojan. Management problems resulted in avoidable costs that should be borne by shareholders, not ratepayers.

## Trojan Key Dissallowance Part 2

We adopt TBA's finding that PGE behaved prudently with respect to the steam generator degradation. However, we disallow the steam generator costs incurred since 1991 and exclude the cost of replacing the steam generators from the imputed costs of running Trojan in the net benefits analysis. Although PGE's behavior was not faulty, PGE and the ratepayers are the only two parties to whom we can assign or impute steam generator costs. As between those two parties, PGE is better situated to recover its costs from the manufacturer of the steam generators. Moreover, it is fair that shareholders bear some of the consequences of management investment decisions. 

## Trojan Key Part 3

These conclusions result in a disallowance of 13.0 percent of the remaining Trojan costs, which will be borne by shareholders, not ratepayers. That result approximates a scenario in which Trojan was reasonably operated and managed. In the main, the disallowances correct for avoidable costs. 

## Trojan Key Part 4

PGE would incur decommissioning and transition costs regardless of when the plant was taken out of service, and the company has already been paying into a decommissioning fund. Because Trojan was shut down before the end of its license life, however, payments into the fund will have to increase for a time.

## PacifiCorp Wind Projects

+ Many projects but two "Rolling Hills" and "Glenrock" were very close.
+ Appeared that project:
    + Avoid bidding rules and other standards used to show prudence.
    + The capacity factor, average divided by nameplate, was only 31%, which is very low for wind in WY.
    + Rushed to get tax credits and meet the new Renewable Portfolio Standard

Acronyms:

+ Industrial Customers of Northwest Utilities (ICNU)
+ Renewable Adjustment Clause (RAC)

## Rolling Hills Key Part 1

Where the utility avoids the Guidelines, the burden of producing evidence remains with the utility. Pacific Power bears that burden of producing evidence in this case that its actions were prudent.

...

Because we find that Pacific Power failed to prove that it prudently acquired the Rolling Hills project, all costs associated with that project are excluded from the RAC cost recovery mechanism.

## Rolling Hills Key Part 2

ICNU suggested that Pacific Power be allowed to “cure” its “imprudence,” depending on the results of a future competitive bidding process. The finding that the Company failed to prove the prudence of its Rolling Hills project acquisition in this case applies only to the Company’s right to recover the costs of these projects in this RAC. Future ratemaking treatment of the Rolling Hills project will be taken up as appropriate.

## Rolling Hills Dissent by Beyer (Now OR Senate)

Not putting the Rolling Hills investment in rate base allows the Company to attempt to recover its investment by selling Rolling Hills output in the market or, perhaps, bidding the project or its output into a subsequent request for proposal to see how it stacks up against the competition.


# Regulated Rate of Return

## What we will look at

+ The effects of capital structure on the rate of return
+ The rarity of using actual structure and a framework for choosing one in a regulatory framework.
+ Technical problems:
    + Subsidiarys
    + Used assets
+ Three ways to estimate ROE and a critique.

## Earnings Volitility and Debt

The capital structure plays a big part in the return on common equity (ROE).

Consider a firm with:

+ Some capital, $K$.
+ A return on assets, $\beta$, that is random with a mean of 10% and a known standard deviation, 3%.
+ Some, $\alpha$, of the capital was funded by bonds that have an interest rate of 8%.
+ There are no other costs

## Earnings Volitility

+ When the firm runs, profits should be, $\beta K$.
+ Then when you pay the bond holders interest you have, $\beta K - .08 \alpha K$.  
    + $\alpha K$ is the capital financed by bonds
    + $.08 \alpha K$ is the interest.
+ Dividing by the capital owned by shareholders, $(1- \alpha)K$ gives the return on equity

$$ROE = \frac{\beta K - .08 \alpha K}{(1-\alpha) K}$$

## Simulated Earnings Volitility

```{r, include=FALSE}
# same beta for everyone
beta <- rnorm(10000, mean = .1, sd = .03)

ROE <- function(alpha ,theBetas) {(theBetas - alpha*.08)/(1-alpha)}

#Test
#ROE(.5, beta)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(reshape2)
ROES <- data.frame(Alph0 = ROE(0,beta), Alpha1 = ROE(.1,beta), Alpha2 = ROE(.3,beta), Alpha1 = ROE(.3,beta), Alpha4 = ROE(.4,beta),Alpha5 = ROE(.5,beta),Alpha6 = ROE(.6,beta), Alpha7 = ROE(.7,beta),Alph8 = ROE(.8,beta),Alpha9 = ROE(.9,beta))

d <- melt(ROES)

ggplot(d,aes(x = value)) + 
    facet_wrap(~variable) + 
    geom_histogram(binwidth = .015)+geom_vline(xintercept = 0, color="red")
```


## Volitility

+ As the debt ratio, fraction of capital funded by bonds, increases:
    + The average return increases.
    + The variance of returns increases.
    + The probability of negative returns increases


## Regulated rate of return

The usual system for the regulated rate of return is to use a weighted average of the returns on all sources of funds.  In our simple model, we have just bonds and equity.

$$RRR = \alpha .08 + (1-\alpha) ROE$$

Clearly, the mix is a choice variable for the firm but new bond and stock issuance typically need to go through the regulator.

## Bond Rate

The bond rate is usually not controversial:

+ Bonds issued by the utility complete with other firms on the basis of the probability of default.
+ Bonds come with a face value, usually 1K and a coupon rate.
+ If the coupon rate is too low for the risk the price of the bond falls, i.e., they trade at a discount.
+ If the coupon rate is too high the price of the bond rises, i.e., they trade at a premium.
    
The number used is called the yield to maturity which is just the internal rate of return on the bond.

## Yield to Maturity

Simple case of a bond:

+ You buy now for $P_0$
+ Has face value of $P$
+ Matures in $N$ years.
+ No coupons.  These are typically purchased for way less than face value

$$\left( \frac{P}{P_0} \right)^{\frac{1}{N}} -1$$
The case with coupons is more complex but you are finding the internal rate of return for the current purchase price and the face value and the coupon payments. EC314 Material if you are interested.


## Where things Get Ugly

+ The capital structure is a choice and you can manipulate the RRR by changing the capital structure.
+ The ROE is circular:
    + The value of the stock is determined by prices and profits
    + Prices and profits are determined by the revenue requirement
    + Which is determined on the change in the value of the stock and dividends
+ Key point, you should not really use the firm's own ROE and capital structure, but one constructed from what similar firms with competitive pressure, a quasi-experimental control group. 


# Return on Equity (ROE)

## Usual Methods and an Unavoidable Assumption

Methods:

+ Discounted Cash Flow (DCF) 
+ Capital Asset Pricing Model (CAPM)
+ Risk Premium Model (RPM)  _We will not cover._

Sitting under all of them is one of the efficient market assumptions. 

BTW a nice discussion of ROE be found at http://stats.lib.pdx.edu/proxy.php?url=http://www.sciencedirect.com/science/article/pii/S1040619011001722


## Three Basic Kinds of Efficient Market Assumptions

Usefulness of information to predict future prices

+ Weak: All past price data will not help.  
+ Semi-Strong: Public data does not help
+ Strong: No data public or private can help

## Grampa Ish and Betting on Horses

+ You don't know who will win.
+ Calculate your own odds of each horse.
+ Bet the horse that is paying off more than you think it should.
+ You win more often if you have your grandson talk to the jockeys.

## Behavioral Finance 

+ Behavioral Economics has a brother.
+ There are plenty of anomalies
    + Monday Effect, French (1980)
    + January Effect, Roll(1983)
    + Firm Size, Banz(1981)
    + Mean Reversion, DeBondt and Thaler (1985)
    + Momentum, Jegadeesh (1990)
    
+ Anomalies get smaller after a paper about it is published.
+ Many critiques have to do with statistical details.

## Comparable Data

The intent is to have observations of a firm just like the one being regulated but without the effect of regulation.

+ The intent is a quasi-experimental control.
+ Comparability is easier to work with for populations but harder for an individual.
    + There is no perfect match
    + The Parable of the Cookie and Parent's Problem.

## Typical Variables Used to find matches

+ Same industry -- Duh
+ Bond rating -- Moody's, S&P is normal and there is a short term and long term rating, but they don't overlap
+ Beta (A measure of market risk), if you are *not* doing CAPM
+ Market Capitalization, Stock price times shares outstanding
+ Fraction of revenues from regulated operations, There is a regulated and a merchant generation side for the most part.  
+ MORE?

## Sample From a FERC Case

They spent 129 pages on the inclusion of basically one observation.

https://www.ferc.gov/CalendarFiles/20160928194709-EL14-12-002.pdf

The Commission uses the following standards to select the proxy group: (1) a national group of companies considered electric utilities by Value Line Investment Survey (Value Line); (2) the inclusion of companies with credit ratings no more than one notch above or below the utility or utilities whose rate is at issue; (3) the inclusion of companies that pay dividends and have neither made nor announced a dividend cut during the six-month study period; (4) the inclusion of companies with no major merger activity during the six-month study period; and (5) companies whose DCF results pass threshold tests of economic logic.


## Number of Observations

In order to establish a proxy group, the Presiding Judge reviewed the DCF determined cost of equity for 42 companies. The Presiding Judge determined that 37 of those companies should be included in the proxy group. Of those companies, the lowest cost of equity was Public Service Enterprise Group’s 7.23 percent and the highest cost was TECO’s 11.35 percent


## What?

+ You can estimate the standard deviation as $\frac{max - min}{4}$ in this case, $\frac{(11.35 - 7.23)}{4} = `r (11.35-7.23)/4`$. 
+ The standard deviation of the mean is $\frac{`r (11.35-7.23)/4`}{(37)^{1/2}} = `r ((11.35-7.23)/4)/sqrt(37)`$.  
+ That implies that the population mean is within  +/- `r ((11.35-7.23)/4)/sqrt(37)*2` of the mean.
+ Clearly, if they had a larger proxy group they would have a larger N and a larger $\sqrt{N}$ and less uncertainty about the mean.

They need a better definition of "close" for more defensible number but the current battle is over inclusion of a small number of observations.

## Quasi-Experimental Methods is Hot in Econ

+ Many fields have very strong standards for establishing causality
+ We often use
    + Coarsened Exact Matching
    + Propensity Score Matching (General)
    + NN matching
    + Kernel ...
+ Regulators are still not there with this.

Key observation is to use several methods to get a reasonable range.  If a proposed mix or ROE is in your range, stipulate.

## Picking Comparable Firms

You need some measure of sameness but there are complications.

+ With _categorical_ or _ordinal_ variables like bond rating it is easy to tell when same, AAA Bond, 
    + but is a AA bond rating more similar to an AAA or a A bond rating? 
    + What if you have several categorical variables and not all of them match?
    
+ With _continous_ variables you never get an exact match, but
    + How close is close?
    + How measure closeness when there are differences in more than one thing, market capitalization and beta, for example?

## Exact matches Categorical and Ordinal

+ Most data will have a mix of continuous and categorical data
+ Exact matches for categorical or ordinal data is easy, "Is it the same" or as you saw with FERC, one ordinal category different.


## For continuous data

Take inspiration from optimal bandwidth in histograms.

+ Start with a broad category, all electric utilities without mergers and acquisitions that provide dividends.
+ Collect the data of interest, say beta
+ Make a histogram and choose boxes by formula
    + Sturges $\lceil \log_2 n \rceil +1$
    + Rice $\lceil 2n^{1/3} \rceil$
    + Many many more

+ Firms in the same box are comparators
+ But this only works for one variable

## Mahalanobis Family

Mahalanobis distance is at the heart of many of many techniques that measure closeness for multiple continuous variables.

Intuition:

+ If the data has a big range, small differences _don't_ matter.
+ If the data has a small range, small differences _do_ matter.
+ Distance should be based on the inverse of the variance, $\frac{1}{\sigma^2}$.
+ In multiple dimensions variance is covariance, $S$, a matrix, and should be based on the inverse, $S^{-1}$.

$$d(x,y) = \left( (x-y)S^{-1}(x-y) \right)^{1/2}$$

## Intuition

Suppose you are looking at how long it would take to walk somewhere.

+ No correlations between directions and the variances.  It takes equal time to walk any direction.
+ No correlations between directions but the variances are different.  You are in a valley and two directions, East and West or North and South, are up hill.
+ With correlations and unequal variances. You are in a valley but it can have any orientation. NNW/SSE etc.


You still have to decide how close is close and that is your choice.

## Mahalanobis is reused

+ Is at the heart of propensity score matching and other advanced econometric techniques. 
+ Also used to create indexes, like the Chinn-Ito index which measures country's degree of capital account openness.
    + You start with $S$ and do a spectral decomposition also called, Eigen decomposition.
    + Use the first eigen vector as the weights.


## For Pure Categorical Data

+ Many metrics in common use.
+ Count of common categories is very common.
    + {blond, blue, curly} and {blond, blue, straight} share two.
    + {Red, blue, curly} and {blond, blue, curly} also share two.
    + Counts all characteristics as equal importance.
+ Convert to dummy variables and use Mahalanobis
    + Harder to do
    + Does not treat all as equal importance

## Dummy Variable

|Person| Red | Blond| Blue| Brown| Straight | Curly|
|-----|----|----|----|----|----|----|
|A |  0 | 1 | 1 | 0 | 0 |1|
|B | 0 | 1 | 1 | 0 | 1 |0|
|C | 1 | 0 | 1 | 0 | 1 |0|

You need a lot of data for the covariance matrix, more than the sum of the categories squared plus the sum of the categories.  For this example, 36+6 = 42, is the minimum.

## Again

This is not generally in introduction to econometrics.

## Discounted Cash Flow (DCF)

This is also called the Gordon Growth Model or the Dividend Discount Model.

$$k = \frac{D_0  (1+g)}{P_0} + g$$

+ $D_0$: Current Dividend
+ $P_0$: Current Price of Stock
+ $g$: Forecasted growth rate of dividend and the growth rate in the price of the stock.  
+ $k$ required rate of return

The book has a typo, or an odd time convention I am missing.

## Understanding it

Start with the idea that the price of an asset is the present value of the constant dividend stream.

$$P= \sum_{t=0}^\infty \frac{D_0}{(1+k)^t}$$
Now let the dividends grow at a rate of $g$.


$$P= \sum_{t=0}^\infty \frac{D_0 (1+g)^t}{(1+k)^t}$$
This is an infinite geometric series.

## Trick from Calc 2 Sequences and Series

I'm starting the sum at time 1 not time zero.

$$\sum_{t=1}^\infty \frac{(1+g)^t}{(1+k)^t}= \frac{1}{1 - \frac{(1+g)}{(1+k)}}= \frac{1}{\frac{(1+k)}{(1+k)} - \frac{(1+g)}{(1+k)}}= \frac{1}{\frac{(k-g)}{(1+k)}}= \frac{(1+k)}{(k-g)}$$

So, to convert to summation starting at zero multiply by $\frac{(1+g)}{(1+k)}$

$$\frac{(1+k)}{(k-g)}\frac{(1+g)}{(1+k)}=\frac{(1+g)}{(k-g)}$$

## You then find

$$P= D_0\frac{(1+g)}{(k-g)}$$
Solve for k, which is the cost of capital that you are looking for.

$$P k -Pg = D_0 (1+g)$$
$$\frac{Pk}{P}=r=\frac{D_0 (1+g)}{P} + g$$

## Gotchas

+ $g<r$ Your dividend growth rate must be less than the return on capital or else you crash the firm in finite time.

+ More than 1-to-1 change in k with changes in g.

$$\frac{\partial k}{\partial g} = \frac{D_0}{P} + 1$$


##  Where to get the parameters

+ First you need to choose time steps.
    + Check with your regulator
+ Usually you use annual.
    + Nice because you can use annual values for $g$ and $D_0$
    + Also less complicated because you don't have to deal with autocorrelation of $P$.
+ Prices change minute by minute.
+ Dividends change annually.


Often use annual values, and using the average closing price or the last closing price for $P$

## But $g$?

+ g is often a blend of a few things.
+ FERC uses a five-year forecast for that firm in a weighted averaged with GDP growth.
+ Forecasts for publicly traded firms are fairly easy to get either through paid or unpaid sources.

+ But, lets be clear, $g$ is a random variable with significant noise.

## Example of $g$ going bad.

+ Start with just GDP forecast uncertainty.  You add uncertainty on top of that.
+ CBO says a standard deviation of 1.3% is average for five year with expected growth of between 2% and 2.4%.  Use 2.4% to give the benefit of the doubt.
+ A normal dividend rate is 2.43%
http://www.dividend.com/dividend-stocks/utilities/electric-utilities/


$$r=0.0243(1+g) + g ~with ~g \sim N(.024, .013 )$$


##  Histogram

```{r, include=FALSE}
gg <- rnorm(10000, mean = .024, sd = .013)

rrr <- .0243*(1+gg)+gg

```

```{r}
plot(density(rrr))
summary(rrr)
```



## More Problems with DCF

+ Capital structure can move this around so comparators have to have similar debt ratios and the bonds need to have similar yield to maturity.
+ Tends to underestimate values by a factor of 4 when compared to the value of a spark-spread option.
+ Spark Spread
    + Spark Spread is the the difference between the price of the fuel and the price of electricity.  The gap is is the value added by the generator.
    + Assumes crazy things like, instant on/off power plants, zero fixed costs, and constant heat rate (BTU/kWh)
+ Sale of CA generation assets provided more evidence that this was going to value things low.


## CAPM 

+ You can do a full class on just the Asset Pricing Model.
+ CAPM is ancient, 1961, and has in many places been replaced. I learned it as a special case of when looking at no-arbitrage models.
+ You can get it from a theoretical model but mostly it is thought of as an empirical relationship.

## CAPM Key Ideas

+ You are trying to build a portfolio with as high a rate of return as possible given the risk you face.
+ It is _mostly_ true, if a stock is more variable it should have a higher return but:
    + Insurance is very variable, but pays off big when other things go bad.
    + It is valuable because it is negatively correlated with everything else.
+ More accurately, if a stock is _possitivly correlated_ with the rest of the market, then if it is more variable it should have a higher return.    


## The One Parameter Model

$$E(R) = R_f + \beta \left[ E(R_m) -R_f \right]$$

+ $E(R)$: Expected rate of return on the security
+ $E(R_m)$: Expected rate of return on the market,S&P 500 is common.
+ $R_f$: Risk free rate, usually the 30-Day Treasury bill.
+ $\beta$: Yes, they call it "beta" how market risk, everything moving at once, is reflected in the price of this stock.
    + If $\beta = 0$ a 1% increase in the market return increases the stock by the same 1%.
    + If $\beta < 0$ Then the change in return is less than the market.

## Implement as Regression

$$R_i - R_f  = \alpha + \beta \left[ R_m -R_f \right] + \epsilon$$

+ On the left subtract the risk free rate from the rate of the stock you are evaluating.
+ on the right subtract the risk free rate of return from the market return.
+ $\alpha$ is how well the firm did for the risk it faced.  
    + $\alpha =0$ as well as the market
    + $\alpha >0$ better than the market.

Use:

+ Use data from the other firms then
+ Use the model to forecast what the return on your firm should be. 

## Many Variations

+ Without risk-free rate, Black (1972)
+ Lifetime consumption, Merton (1973)
+ Dividends, taxes, Brennan (1970)
+ Foreign exchange, Solnik (1974)
+ Inflation, Long (1974)

## What Can Trip You Up

+ Influential observations
    + Relationship driven by just a few outliers.
    + Check with Cooks Distance or leverage (Diagonal of projection matrix)
    + You can drop these or
    + Use Least Absolute Deviation estimator. 
    
+ Multiple observations of individual firms
    + People often leave them in because they think more observations is better.
    + The observations are correlated with each other.
    + Either avoid or use some panel data methods.

## How can this be worse?

+ Still has the assumption that the capital structure, debt ratio, is the same in all firms.
+ Sometimes you have to dig back in the income statement and find
    + Earnings before interest taxes and depreciation, EBITD
    + Total Assets
    + Debt ratio
    + The tax rate (t)
    + This give "return on total assets", $\frac{EBIT}{Assets}$, rather than "return on common equity".
+ Run the regression as before but adjust the resulting $\beta$.
    + $\beta_l = \beta \left[1 + (1-t) (1-Debt~Ratio)\right]$
    + Assumes no noise in the debt ratio and tax rate but mostly works.
    
## Next Week 

+ Start reading chapter 6.
+ We need to decide if you want a regression based homework.

