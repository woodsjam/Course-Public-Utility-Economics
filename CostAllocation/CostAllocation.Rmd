---
title: "Cost Allocation"
author: "James Woods"
date: ""
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(scipen=999)

```



## Abstraction of Costs

Consider the load shape of a customer and the load shape of the entire utility.

The individual:

+  Integrate the load for individual, i, $kW_i$, to get $kWh_i$. $\int kW_i(t) dt$
    + But the cost of electricity is not the same throughout the day, $\int kW_i(t) p(t) dt$
    + Price goes up when lots of people want electricity at the same time. 
+ Look at the individual peak, $\max kW_i$
    + Associated with the cost of the distribution system close to an individual
    + But, if an individual down the street has a higher peak demand, the you benefit because fewer local outages.
+ Sunk costs of you, e.g., service head, meter, Depending on jurisdiction
+ Fixed cost because of you, e.g., bill sent to you
    
    
## Abstraction of Costs (Con't)

The System:

+ Look at the system peak, $\max_t(\sum_{\forall i} kW_{i,t})$
    + Transmission and generation must be sized for this.
    + You contribute a lot to these costs if you use a lot at that time but little if you don't
+ System Sunk Costs
+ System Fixed Cost


Note that many of these costs are shared, like a public good, or that the action of some individuals has positive and negative effect on others, like an externality.

## Our Approach

+ Start with a pure economic approach that is rooted in mechanism design and game theory for joint and common costs.
+ This will help us evaluate some of the problems with common practice and some vague statements in the book.
+ We will return to common practice with focus on choosing the proper volume index for each kind of joint/common cost.

## Mechanism Design and Game Theory Approaches

## The Regulatory Allocation Mechanisms

+ Often approximate a rules from mechanism design called the Clarke Pivot Rule and cooperative game theory called the Shapely Value.
+ Both try to get at incremental cost
+ The rules have many advantages but there are problems.
+ Most of the pure econ material does not address time, much in the same way the "equivalent peaker" methodology ignores time.


## Mechanism Design

+ Mechanism design is game theory backwards.
    + Given a desired objective, what would a game that gives you that objective look like.
    + The game has constraints, voluntary participation, incentive compatible, truth revealing, budget neutral, etc.
+ Main body of work started with Vickrey in 1961

## Vickrey-Clarke-Groves Mechanisms

This is part of a large class of mechanisms that encourage actors to reveal private information, beliefs for example, and achieve a socially-optimal solution.

The general pattern is:

+ Agents report the value of all the choices.
+ The mechanism then chooses the choice that maximizes social welfare.
+ Gives everyone identical money equal to the value of the *other* agents combined.

The trick is figuring out how to implement the last step.

## Step 3? 

The idea is to align the individual incentives with social welfare.

+ Rule three could be to give the sum of everyone's Consumer Surplus.
+ Clearly, not budget neutral.


## The Clarke Pivot Rule

This is step 4.

Charge the player the difference between social welfare if they didn't exist and social welfare when they exist.

+ This is the externality of the player.
+ Maximizes social welfare
+ Individually rational, the benefit of participating and being charged is greater than not participating and not being charged.
+ You only pay if you play

## Odd things to watch for

+ This does induce people to be truthful about their valuations, but beyond the scope of the course.
+ Rarely, do the bids yield exactly the right revenue.
+ Accounting style cost splitting is a special case.  Only when there is no change in the social choice.

## Clarke Pivot

+ Do we get a painting with cost $20?
+ Two agents, A, B with true benefits of, ${6,10}$.

+ A
    + With A, the value to the others is $6+10 =16$.
    + Without A, the value of the painting is still $20, the avoided cost.
    + A is charged $4.
+ B
    + With B, the value to the others is still $16.
    + Without B, the value of the painting is still the avoided costs, $20.
    + B is charged $4.
    
We sell the painting and give the money back.

## Clarke Pivot Example 1

+ Do we get a painting with cost $14?
+ Two agents, A, B with true benefits of, ${6,10}$.

+ A
    + With A, the value to the others is $6+10 =16$.
    + Without A, the value of the painting is still $14, the avoided cost.
    + A is charged $2.
+ B
    + With B, the value to the others is still $16.
    + Without B, the value of the painting is still the avoided costs, $14.
    + B is charged $2.
    
Does not raise enough to pay for the painting and treats both agents the same.  Both are pivotal. Without them, the choice would flip from keeping the painting to not keeping it.


## Clarke Pivot Example 2

+ Do we get a painting with cost $14?
+ Two agents, A, B with true benefits of, ${10,12}$.


+ A
    + With A, the value to the others is $10+12 =22$.
    + Without A, the value of the painting is still $14, the avoided cost.
    + A is charged $8.
+ B
    + With B, the value to the others is still $22.
    + Without B, the value of the painting is still the avoided costs, $14.
    + B is charged $8.
    
Raises more than enough for the painting  and treats both agents the same.  Both are pivotal, without them, the choice would flip from keeping the painting to not keeping it.


## Clarke Pivot Example 3

+ Do we get a painting with cost of $7?
+ Three agents, A, B and C with true benefits of, ${1,3,5}$.

+ A
    + With A, the value to the others is $1+3+5 =9$.
    + Without A, the value of the painting is still $3+5 =8$.
    + A is charged $1.
+ B
    + With B, the value to the others is still $1+3+5 =9$.
    + Without B, the value of the painting is the avoided costs, $7.
    + B is charged $2.
+ C
    + With C, the value to the others is still $9.
    + Without C, the value of the painting is still the avoided costs, $7.
    + C is charged $2.
    
Does not raise enough to pay for the painting, but charges B and C more because they were pivotal.
    
    

## Clarke Pivot Example 4

+ Do we get a painting with cost of $14?
+ Three agents, A, B and C with true benefits of, ${9,10,12}$.

+ A
    + With A, the value to the others is $9+10+12 =31$.
    + Without A, the value of the painting is still $10+12 =22$.
    + A is charged $9.
+ B
    + With B, the value to the others is still $9+10+12 =31$.
    + Without B, the value of the painting is $9+12 =21$.
    + B is charged $10.
+ C
    + With C, the value to the others is still $31.
    + Without C, the value of the painting is $9+10=19$.
    + B is charged $12.
    
Raises enough to pay for the painting and everyone pays their personal benefit since they would not change the social choice.  Nobody is pivotal.


##  Observations

+ As the social benefits get larger relative to price the more revenue is collected. Examples 2 and 4.

+ If a player is not pivotal, they pay their marginal valuation.

+ Pivotal players are treated the same.

+ Implies that even when you get the right metric, peak, coincident peak, volumetric, etc., that proportional sharing of costs is not always right.
    + It does work when the individual or group does not pivotal and induce the need for more infrastructure.

+ Most efficient systems will fail on a fairness criteria.

## Cooperative Game Theory Point of View
    
The Shapley Value comes from cooperative game theory. It is a unique way of distributing the gains from cooperating that has nice properties.

+ Efficient:  All the gains/costs are distributed with none left over.
+ Symmetric: If two agents are equivalent they get the same payoff.
+ Linear: You can subdivide the coalition and the system still works.


## Obligatory formula 

The amount that player i gets, $\phi_i(v)$, is some function of what they all produce together, $v$. 

$$\phi_i(v)=\sum_{S \subseteq N \setminus
\{i\}} \frac{|S|!\; (n-|S|-1)!}{n!}(v(S\cup\{i\})-v(S))$$



Ignore this. The math notation gets in the way.

## Shapely Intuition

+ You have a bunch of players that will cooperate with each other.
+ They join the team in random order.
+ When they join they demand $(v(S\cup\{i\})-v(S))$ which is the benefit to the coalition of them joining.
+ Each individual gets the average from all possible orderings, which is what the $\sum_{S \subseteq N \setminus
\{i\}} \frac{|S|!\; (n-|S|-1)!}{n!}$ term does.


## What Does This Have to Do with Costs 

+ If you have several customers that are pivotal, causing the utility to make added investments it is unclear how to allocate the incremental costs. 
+ Shapely averages over all possible orders.
+ They see a reduction in cost from non-cooperation.


If you need to balance a budget and fully allocate costs, this gives the best welfare result.

## Cost Allocation With Shapely

+ Two new customers with:
    + $v(\{1\})=10$
    + $v(\{2\})=12$
    + $v(\{1,2\})=18$
+ Notice the joint costs are subadditive.

+ Two arrival orders 1,2 and 2,1
    + 1 then 2: 1's contribution 10, 2's is $18-10=8$.
    + 2 then 1: 2's contribution 12, 1's is $18-12=6$
    
Now average for player 1 is $(10+6)/2 =8$ and player two is $(8+12)/2 = 10$.  


## Shapely Observations

+ Works when costs are subadditive, natural monopoly style.
+ If costs are super additive or constant returns to scale, then you should not have common or joint costs.
+ Still requires a what-if, least cost alternative plan for each. 


## Back to Accounting Style 

+ FERC has a well developed Uniform System of Accounts. http://www.ecfr.gov/cgi-bin/text-idx?c=ecfr&SID=054f2bfd518f9926aac4b73489f11c67&rgn=div5&view=text&node=18:1.0.1.3.34&idno=18
+ The system of accounts
    + Keeps the regulated separate from the unregulated.
    + Helps with the easy to functionalize expenditures, the new transmission line is in the transmission category

## In General

You classify costs three ways

+ Variable: Change with sales
+ Fixed: Uncorrelated with sales
+ Customer: Very direct

Common and Joint Costs are the hard ones.

For Common Costs (Same thing at same time)

+ You need to a good volume index
+ Allocate proportionally

## The Right Volume Index

+ A volume index is a generalization of quantity that allows you to measure more than one thing at once.
+ Many volumes have more than one logical volume index, for example a restaurant.
    + Tops -- Good for wait staff
    + Plates -- Balance between wait staff and food costs.
    + Revenue -- Good for food costs
+ Utilities usually use some combination of
    + Customer counts
    + Coincident peak, kW.
    + Volume, kWh.
    + But will use other similar costs when the right index is unclear: KN, Mass, Distrigas

Allocation is usually proportional with some movement for fairness.


## For Hard Joint costs

Non-allocable accounts, for example, accounting costs, office rents, etc.
 
+ Kansas Nebraska (KN) -- the ratio of direct labor and capital investment of each division to total direct labor and capital investment. 
+ Massachusetts -- the ratio of direct labor, capital investment and gross revenue of each affiliate to total direct labor, capital investment and gross revenue. 
+ Distrigas --  the ratio of direct labor, capital investment and net operating revenue of each affiliate to total direct labor, capital investment and net operating revenues.

Basically, if the shared costs are across several corporate entities, use Massachusetts or Distrigas, otherwise KN


## Management Fees

+ These are fees charged to the regulated part of a firm by the unregulated part.
+ This may be an avenue for cross-subsidization.
+ Hedge funds use this mechanism to pull profits out of a firm they took over without pulling profits directly out of the firm.

## Methods

The book gives a few worked examples but the NARUC Electric Utility Cost Allocation Manual (http://pubs.naruc.org/pub/53A20BE2-2354-D714-5109-3999CB7043CE
) is more comprehensive.  


The book mentions 

+ 4-CP which averages the coincident peak for four seasons and tries to use this for kW type measures
+ Inverse Load factor, $\frac{maximum ~ use}{average ~ use}$, to say that kW measure should be charged more to those that are more volatile.
+ Equivalent peaker, which, I think, tries to split the difference between the two points of view.

But misses key things like

+ Hourly models
+ Loss of Load Probability Models (LOLP)


## Data Used to Allocate Joint/Common Costs

+ Peak Load (kW) in period
    + Maximum load in kW in each rate class
    + Can be at different time than other rate classes.
+ Coincident Peak load (kW) in period
    + The load at the highest system peak in the period.
    + Not necessarily the highest load for that class, commercial can be pretty low at the coincident peak if the peak is in the evening
+ Use in period (kWh)

##  Periodicity of Peak Observations

+ Some methodologies require peak:
    + Monthly
    + Quarterly
    + Annually
    
The monthly and quarterly figures are often averaged but be careful, max and sum do not always work well together.

## Monthly Coincident Peaks for Domestic Service

```{r, message=FALSE, warning=FALSE, include=FALSE}
Periodicity <- data.frame(Month = 1:12, DOM = c(3887,3863,2669, 2103,2881,3338,4537,4735,4202,2534,3434,4086))

```

```{r}
library(knitr)
kable(Periodicity)
```

Annual peak is `r max(Periodicity$DOM)` and happens in month `r Periodicity$Month[which.max(Periodicity$DOM)]`.  The average of the coincident peaks is `r mean(Periodicity$DOM)`.

## Now Look at Quarterly


```{r}
library(knitr)
kable(Periodicity[1:3,])
```

The coincident peak in the first quarter is `r max(Periodicity[1:3,])`.  You can also see the max of the other quarters are `r max(Periodicity[4:6,])`, `r max(Periodicity[7:9,])`, and `r max(Periodicity[10:12,])` respectively.

The average of those four peaks is `r mean(max(Periodicity[1:3,]),max(Periodicity[4:6,]),max(Periodicity[7:9,]),  max(Periodicity[10:12,]) )`.

## Compare those Average Coincident Peaks

+ Annual Peak `r max(Periodicity$DOM)`
+ Average of Quarterly Peaks `r mean(max(Periodicity[1:3,]),max(Periodicity[4:6,]),max(Periodicity[7:9,]),  max(Periodicity[10:12,]) )`
+ Average of Monthly Peaks  `r mean(Periodicity$DOM)`

Those are pretty different, but remember all the other rate classes will have similar differences.  The average maximum values decreases as you more finely subdivide the time periods.

## Why Use One or the Other?

Remember your objectives.  You are trying to make sure that the capacity is there so that your have a loss of load probability of 1 day in 10 years.

+ Ideal, the demand in the area does not change and you can look the peak day in the last 10 years and say that you can just meet that.
+ But, load changes because industry, population, incomes, installed equipment, etc., all change over time.
+ The common largest unit of analysis is the year but the peak is usually forecasted many years out as part of integrated resource planning.


But, do you want to allocate costs based on one hour in a year?

+ It could be a very odd hour.
+ Industrial consumers may have done some demand response and shut off equipment.
+ Maybe using more than one hour in a year is a good idea?


## Balance Your Risk

+ The goal is to get as good an estimate as possible for the share of peak demand for each rate class.
+ More *similar* observations gives greater certainty about that share.
+ If summer and winter shares are similar, averaging them is not a problem.
+ If monthly shares are similar, averaging them is not a problem.


## Many Criteria in Common Use

+ Use all hours where the demand is within 5% or 10% of annual peak.
+ Use all hours where the loss of load probability (LOLP) is above a certain threshold.

The method will depend on utility and jurisdiction but always keep in mind that the objective is not to estimate the rate classes load at the system peak, but their share of the load when it does peak.

## Warning 1

Make sure all data is from the same frequency, hour, 15-minute, 5-minute data.  Maximum data at higher frequencies, 5-minute in particular is often much higher than hourly frequency.  The lower frequencies are averages of the higher frequencies and averages hide extreme values.

Mercury has a daytime average temp of 800F and a nighttime temperature of -290F and an average of 332F.  If you design your ship for the average, you will be fried or frozen in no time.

## Warning 2

Make sure all your estimates or data come from the same point in the system.

+ At the meter
+ At the substation
+ At the generator

There are line losses because of electrical resistance. Line loss increases as temperature increases, which is often when demand is the highest.

+ If at meter, there often a topping out of use with increased temperature. $\frac{d}{dt}<0$
+ Often nutral at the substation $\frac{d}{dt}=0$
+ But looks like a positive second dirivative at the generator $\frac{d}{dt}>0$


## Worked Examples of Allocation

This is actually from the "Electric Utility Cost Allocation Manual" which uses old SCE data from 1988. Warning, the publication reverses some columns.

+ Loads in MW
+ Energy is in millions of kWh
+ NCP is the peak for the customer class.
+ Example is rigged so that the peak of the customer class is not at the system peak.

## System Data

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(knitr)

AYear <- data.frame(Month = 1:12, SystemkWH = c(5610,5130,5590,5400,5670,5860,6580,6910,6410,6110,5500,5700), SystemCP = c(11074,11126,10716,11178,11779,12726,14453,15379,15842,13032,11337,11705), SystemNCP = c(10520,10570,10180,10620,11190,12090,13730,14610,15050,12380,10770,11120) , CustCP = c(319,315,344,358,403,427,515,520,489,405,336,347), CustNCP = c(337,344,354,361,410,431,524,524,491,405,364,355), CustkWh = c(166,153,179,180,210,215,268,271,246,211,169,181) )

```


```{r, echo=FALSE}
kable(AYear[1:4])
```




## Data for one rate class

```{r, echo = FALSE}
kable(AYear[c(1, 5:7)])
```


## Coincident Peak Share (Average Monthly)

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# library(dplyr)
# AYear %>% select(Month, SystemCP, CustCP)  -> CP

CP <- AYear[, c("Month", "SystemCP", "CustCP")]
SumSystem <- sum(AYear$SystemCP)
SumCust <- sum(AYear$CustCP)
Share <- SumCust/SumSystem


```


```{r}
kable(CP)
```


## Single System Coincident Peak (1CP)

+ Find the month with the highest peak and use the system peak and customer coincident peak for that month.

```{r, echo=FALSE}
kable(CP[which.max(CP$SystemCP),])
```


The customer share of the common/joint costs should be $\frac{489}{15842}= `r 489/15842`$.


## Average of 12 Monthly System Coincident Peak (12 CP)

+ Note that you are actually using 12 observations in this.
+ Add up the monthly system peaks.  `r sum(CP$SystemCP)`
+ Add the monthly customer peaks, `r sum(CP$CustCP)`
+ Divide and get the share of common/joint costs, `r  sum(CP$CustCP)/sum(CP$SystemCP)`

Note that this is slightly different from the 1CP method, `r 489/15842`.

## Seasonal Coincident Peak (4 CP)

+ Add up the system peak in each of the four quarters.
+ Note that this is four observations and not 12 or 1.
+ Add up the monthly customer peaks in the same months as the system peak for each of the four quarters.
+ Divide and get the share of common/joint costs.

## 4 CP Calculations

The system peaks in the four seasons are in months 2,6,9,10.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
Season <- AYear[c(2,6,9,10),c("Month","SystemCP","CustCP")]
kable(AYear[c(2,6,9,10),c("Month","SystemCP","CustCP")])
```

The Cust Class share is then just ratio of the sum of these coincident peaks, $\frac{`r sum(Season$CustCP)`}{`r sum(Season$SystemCP)`} = `r sum(Season$CustCP)/sum(Season$SystemCP)`$




## Inverse Load Factor

+ This is intended to get at the variability of loads.
+ The logic
    + Highly variable loads, where the peak is high relative to the average, will require greater capacity than a load with the same average and lower peak.
    + Capacity, the joint/common costs, are driven by peak.
    + Those with more stable loads can be better served by a baseload plant rather than a baseload and peaker plant.
+ The load factor is the ratio of the average load to the maximum load, $\frac{Avg}{Peak}$


Problem is that it does not work when the loads are not on the same scale.

## Inverse Load Factor Steps

+ Find the Annual Peak for for each rate class.
+ Find the Average Annual Demand, aMW in PNW parlance.
+ Divide the Peak by average for each class.
+ Find sum of the inverse load factors.
+ Divide each inverse load factor by the sum of the inverse load factors.

```{r, echo=FALSE}

PeakClass <- max(AYear$CustNCP)
AvgClass <- sum(AYear$CustkWh)*1000/8760
PeakSystem <- max(AYear$SystemCP)
AvgSystem <- sum(AYear$SystemkWH)*1000/8760  

PeakOther <-max(AYear$SystemCP- AYear$CustCP)
AvgOther <-sum(AYear$SystemkWH- AYear$CustkWh)*1000/8760

ClassInvLF <- (PeakClass/AvgClass)
OtherInvLF <- PeakOther/AvgOther
SystemInvLF <- PeakSystem/AvgSystem


```

## Numerical Example

We don't quite have all the data but we can create a Not-Cust rate class, which is just everyone else.  We create a new peak by subtracting the Cust coincident peak from the system peak and subtract the Cust kWh from the system kWh.

+ Data
    + Peak of Cust is `r PeakClass` MW.  This is the non-coincident peak which is slightly higher than the coincident peak.
    + aMW for Cust is `r AvgClass` aMW
    + Peak for Non-Cust is `r PeakOther` MW
    + aMW for Non-Cust is `r AvgOther` aMW

+ Inverse Load Factors
    + Cust Inverse Load Factor, $\frac{`r PeakClass`}{`r AvgClass`} = `r PeakClass/AvgClass`$ 
    + Non-Cust Inverse Load Factor, $\frac{`r PeakOther`}{`r AvgOther`} = `r PeakOther/AvgOther`$
    + Sum of inverse load factors is `r ClassInvLF+OtherInvLF` 

Share for Cust is `r ClassInvLF/(ClassInvLF+ OtherInvLF)`.  See what I mean.  


## Shapely Approach

+ Find the annual peak.
+ Then find what the annual peak would be with only one customer type.
+ Then with all pairwise combinations
+ Then three way and so on.
+ Once you have that data, which is significant, you need full year load shapes.
    + Simulate having the customer types enter in random order.
    + Find the new concident peak as each customer type enters.
    + Find how that customer adds to that peak.
    + Average for each customer type all their contributions to peak load.
    
## Shapely Example

+ We divide the system into two parts, the customer and Non-Cust, just like in the inverse load factor.
+ Data
    + Peak of Cust is `r PeakClass` MW.  This is the NC peak and is in a different month than coincident peak
    + Peak for Non-Cust is `r PeakOther` MW, which is in the same period as the coincident peak.
    + System peak, `r PeakSystem`

Note the difference between the sum of the two peaks and the system peak is small even though the cust peak is in a different month.

## Shapely Calculations

+ Cust First
    + Cust adds, `r PeakClass`, to the load
    + Non-Cust enters the load goes up by (System Peak - Cust Peak) = `r PeakSystem - PeakClass`.
+ Non-Cust First
    + Non-Cust adds, `r PeakOther`
    + When Cust enters the load goes up by (System Peak - Non-Cust Peak) = `r PeakSystem - PeakOther`.
    
+ The average contribution to the load is then for
    + Cust $(`r PeakClass` +`r PeakSystem - PeakOther`)/2 = `r ( PeakClass + PeakSystem - PeakOther)/2`$ 
    + Non-Cust $(`r PeakOther` +`r PeakSystem - PeakClass`)/2 = `r ( PeakOther + PeakSystem - PeakClass)/2`$

```{r, message=FALSE, warning=FALSE, echo=FALSE}

CustShapely <- (PeakClass + PeakSystem - PeakOther)/2 
OtherShapely <-(PeakOther + PeakSystem - PeakClass)/2 

```


Cust share is then $\frac{`r CustShapely`}{`r CustShapely` + `r OtherShapely`} = `r CustShapely/(CustShapely + OtherShapely)`$


## Summary of Load Shares

+ 1 CP  : `r 489/15842`
+ 12 CP : `r  sum(CP$CustCP)/sum(CP$SystemCP)`
+ 4 CP : `r sum(Season$CustCP)/sum(Season$SystemCP)`
+ Inverse Load Factor : `r ClassInvLF/(ClassInvLF+ OtherInvLF)` !!!!!
+ Shapely : `r CustShapely/(CustShapely + OtherShapely)`